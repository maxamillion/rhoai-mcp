# RHOAI MCP Evaluation Configuration
# Copy this file to .env.eval and fill in your values.

# --- Agent LLM Settings ---
# Provider: openai, vllm, or azure
RHOAI_EVAL_LLM_PROVIDER=openai
# Model name for the agent
RHOAI_EVAL_LLM_MODEL=gpt-4o
# API key for the agent LLM
RHOAI_EVAL_LLM_API_KEY=sk-...
# Base URL (required for vLLM/Azure, optional for OpenAI)
# RHOAI_EVAL_LLM_BASE_URL=http://localhost:8000/v1

# --- Judge LLM Settings (for DeepEval metrics) ---
# Model used by DeepEval to evaluate agent behavior
RHOAI_EVAL_EVAL_MODEL=gpt-4o
# API key for the judge (can be same as agent key)
RHOAI_EVAL_EVAL_API_KEY=sk-...
# Base URL for the judge model (if using a custom endpoint)
# RHOAI_EVAL_EVAL_MODEL_BASE_URL=http://localhost:8001/v1

# --- Cluster Settings ---
# mock: Use MockK8sClient with pre-populated data (no real cluster needed)
# live: Connect to a real OpenShift cluster (requires valid kubeconfig)
RHOAI_EVAL_CLUSTER_MODE=mock

# --- Metric Thresholds ---
# Minimum scores for DeepEval metrics (0.0 - 1.0)
RHOAI_EVAL_MCP_USE_THRESHOLD=0.5
RHOAI_EVAL_TASK_COMPLETION_THRESHOLD=0.6

# --- Agent Settings ---
# Maximum number of LLM turns per evaluation scenario
RHOAI_EVAL_MAX_AGENT_TURNS=20
